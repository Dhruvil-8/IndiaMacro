{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00B â€” RBI Macro Data Load & Validation\n",
    "\n",
    "**Purpose**: Load all RBI CSVs, clean columns, wideâ†’long conversion, identify usable macro series\n",
    "\n",
    "**Inputs**: `../data_raw/rbi/*.csv`\n",
    "\n",
    "**Outputs**:\n",
    "- `../data_processed/rbi_macro_all_long.parquet`\n",
    "- Coverage table (series Ã— frequency Ã— years)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:34.142663Z",
     "iopub.status.busy": "2026-02-01T09:26:34.142211Z",
     "iopub.status.idle": "2026-02-01T09:26:35.118240Z",
     "shell.execute_reply": "2026-02-01T09:26:35.116654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBI CSV files found: 8\n",
      "  â€¢ Dailyother.csv\n",
      "  â€¢ Macro-economic Indicators - Fortnightly.csv\n",
      "  â€¢ Macro-economic Indicators - Monthly.csv\n",
      "  â€¢ Macro-economic Indicators - Quarterly.csv\n",
      "  â€¢ Macro-economic Indicators - Weekly.csv\n",
      "  â€¢ otherMonthly.csv\n",
      "  â€¢ otherQuarterly.csv\n",
      "  â€¢ otherWeekly.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "RBI_PATH = Path('../data_raw/rbi')\n",
    "PROCESSED_PATH = Path('../data_processed')\n",
    "PROCESSED_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"RBI CSV files found: {len(list(RBI_PATH.glob('*.csv')))}\")\n",
    "for f in RBI_PATH.glob('*.csv'):\n",
    "    print(f\"  â€¢ {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Frequency Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.178879Z",
     "iopub.status.busy": "2026-02-01T09:26:35.178525Z",
     "iopub.status.idle": "2026-02-01T09:26:35.183893Z",
     "shell.execute_reply": "2026-02-01T09:26:35.182405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency mapping defined\n"
     ]
    }
   ],
   "source": [
    "# Map filenames to frequencies\n",
    "FREQUENCY_MAP = {\n",
    "    'Dailyother.csv': 'daily',\n",
    "    'Macro-economic Indicators - Weekly.csv': 'weekly',\n",
    "    'otherWeekly.csv': 'weekly',\n",
    "    'Macro-economic Indicators - Fortnightly.csv': 'fortnightly',\n",
    "    'Macro-economic Indicators - Monthly.csv': 'monthly',\n",
    "    'otherMonthly.csv': 'monthly',\n",
    "    'Macro-economic Indicators - Quarterly.csv': 'quarterly',\n",
    "    'otherQuarterly.csv': 'quarterly'\n",
    "}\n",
    "\n",
    "print(\"Frequency mapping defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Each CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.188915Z",
     "iopub.status.busy": "2026-02-01T09:26:35.188612Z",
     "iopub.status.idle": "2026-02-01T09:26:35.249080Z",
     "shell.execute_reply": "2026-02-01T09:26:35.247335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Dailyother.csv\n",
      "   Shape: (3922, 8)\n",
      "   Columns: ['Reporting Date', 'NSE S&P CNX NIFTY', 'BSE BANKEX', 'REPO RATE (OVERNIGHT)', 'REVERSE REPO RATE (OVERNIGHT)']...\n",
      "\n",
      "ðŸ“ Macro-economic Indicators - Fortnightly.csv\n",
      "   Shape: (217, 10)\n",
      "   Columns: ['Period', 'Non Food Credit\\n (?  Crore)', 'Investment In India\\n (? Crore)', 'Aggregate Desposits \\n(? Crore)', 'Bank Credit \\n(? Crore)']...\n",
      "\n",
      "ðŸ“ Macro-economic Indicators - Monthly.csv\n",
      "   Shape: (99, 22)\n",
      "   Columns: ['Period', 'Consumer Price Index  (2012=100)', 'Index of Industrial Production', 'Wholesale Price Index (2011-12=100)', 'Consumer Price Index for Agricultural Labourer']...\n",
      "\n",
      "ðŸ“ Macro-economic Indicators - Quarterly.csv\n",
      "   Shape: (32, 5)\n",
      "   Columns: ['Period', 'Overall Balance of Payments Net \\n(US $ Million)', 'International Investment Position Net\\n(US $ Million)', \"India's External Debt - Gross Total \\n (US $ Million) \", 'Gross External Debt\\nPosition']\n",
      "\n",
      "ðŸ“ Macro-economic Indicators - Weekly.csv\n",
      "   Shape: (433, 17)\n",
      "   Columns: ['Period', 'Forward Premia of US$ 1-month (%)', 'Forward Premia of US$ 3-month (%)', 'Forward Premia of US$ 6-month (%)', 'Reverse Repo Rate (%)']...\n",
      "\n",
      "ðŸ“ otherMonthly.csv\n",
      "   Shape: (900, 31)\n",
      "   Columns: [' Reporting Date', 'M1', 'M2', 'M3', 'CREDIT TO THE COMMERCIAL SECTOR BY THE BANKING SYSTEM']...\n",
      "\n",
      "ðŸ“ otherQuarterly.csv\n",
      "   Shape: (64, 61)\n",
      "   Columns: [' Reporting Date', 'ALL INDIA HOUSE PRICE INDEX (Base-Year : Q1:2010-11)', 'BoP - CURRENT ACCOUNT BALANCE INR', 'BoP - CURRENT ACCOUNT CREDIT INR', 'BoP - CURRENT ACCOUNT CREDIT USD']...\n",
      "\n",
      "ðŸ“ otherWeekly.csv\n",
      "   Shape: (578, 5)\n",
      "   Columns: [' Reporting Date', 'CALL MONEY RATE (BORROWINGS) - HIGH', 'CALL MONEY RATE (BORROWINGS) - LOW', 'FOREIGN CURRENCY ASSETS', 'FOREIGN EXCHANGE RESERVES']\n"
     ]
    }
   ],
   "source": [
    "def load_rbi_csv(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load RBI CSV with flexible date parsing.\"\"\"\n",
    "    # Try reading with different encodings\n",
    "    for encoding in ['utf-8', 'latin-1', 'cp1252']:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, encoding=encoding)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and inspect all files\n",
    "rbi_raw = {}\n",
    "for csv_file in RBI_PATH.glob('*.csv'):\n",
    "    try:\n",
    "        df = load_rbi_csv(csv_file)\n",
    "        rbi_raw[csv_file.name] = df\n",
    "        print(f\"\\nðŸ“ {csv_file.name}\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {list(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {csv_file.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardize Column Names & Parse Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.253482Z",
     "iopub.status.busy": "2026-02-01T09:26:35.252682Z",
     "iopub.status.idle": "2026-02-01T09:26:35.360117Z",
     "shell.execute_reply": "2026-02-01T09:26:35.358571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dailyother.csv: 3921 rows, 7 series\n",
      "âœ“ Macro-economic Indicators - Fortnightly.csv: 217 rows, 9 series\n",
      "âœ“ Macro-economic Indicators - Monthly.csv: 99 rows, 21 series\n",
      "âœ“ Macro-economic Indicators - Quarterly.csv: 32 rows, 4 series\n",
      "âœ“ Macro-economic Indicators - Weekly.csv: 433 rows, 16 series\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ otherMonthly.csv: 899 rows, 30 series\n",
      "âœ“ otherQuarterly.csv: 63 rows, 60 series\n",
      "âœ“ otherWeekly.csv: 577 rows, 4 series\n"
     ]
    }
   ],
   "source": [
    "def identify_date_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Find the date column in a DataFrame.\"\"\"\n",
    "    date_candidates = ['Date', 'date', 'DATE', 'Period', 'period', 'Month', 'Quarter']\n",
    "    for col in date_candidates:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    # Return first column as fallback\n",
    "    return df.columns[0]\n",
    "\n",
    "def parse_date_column(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parse various date formats.\"\"\"\n",
    "    # Try multiple date formats\n",
    "    for fmt in [None, '%d-%m-%Y', '%Y-%m-%d', '%d/%m/%Y', '%b-%Y', '%B %Y', '%Y-%m']:\n",
    "        try:\n",
    "            if fmt:\n",
    "                return pd.to_datetime(series, format=fmt, errors='coerce')\n",
    "            else:\n",
    "                return pd.to_datetime(series, dayfirst=True, errors='coerce')\n",
    "        except:\n",
    "            continue\n",
    "    return pd.to_datetime(series, errors='coerce')\n",
    "\n",
    "def standardize_rbi_df(df: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Standardize column names and set date index.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Find and parse date column\n",
    "    date_col = identify_date_column(df)\n",
    "    df['Date'] = parse_date_column(df[date_col])\n",
    "    \n",
    "    # Drop rows with invalid dates\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Drop original date column if different\n",
    "    if date_col != 'Date' and date_col in df.columns:\n",
    "        df = df.drop(columns=[date_col])\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [str(c).strip().replace('\\n', ' ').replace('  ', ' ') for c in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Standardize all DataFrames\n",
    "rbi_standardized = {}\n",
    "for filename, df in rbi_raw.items():\n",
    "    try:\n",
    "        std_df = standardize_rbi_df(df, filename)\n",
    "        rbi_standardized[filename] = std_df\n",
    "        print(f\"âœ“ {filename}: {len(std_df)} rows, {len(std_df.columns)} series\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert Wide â†’ Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.363418Z",
     "iopub.status.busy": "2026-02-01T09:26:35.363098Z",
     "iopub.status.idle": "2026-02-01T09:26:35.497823Z",
     "shell.execute_reply": "2026-02-01T09:26:35.496318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dailyother.csv: 20515 observations in long format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-economic Indicators - Fortnightly.csv: 412 observations in long format\n",
      "Macro-economic Indicators - Monthly.csv: 663 observations in long format\n",
      "Macro-economic Indicators - Quarterly.csv: 1 observations in long format\n",
      "Macro-economic Indicators - Weekly.csv: 6249 observations in long format\n",
      "otherMonthly.csv: 11061 observations in long format\n",
      "otherQuarterly.csv: 681 observations in long format\n",
      "otherWeekly.csv: 2302 observations in long format\n",
      "\n",
      "Total observations: 41,884\n"
     ]
    }
   ],
   "source": [
    "def wide_to_long(df: pd.DataFrame, frequency: str, source_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide format to long format.\"\"\"\n",
    "    # Reset index to make Date a column\n",
    "    df_reset = df.reset_index()\n",
    "    \n",
    "    # Melt to long format\n",
    "    long_df = df_reset.melt(\n",
    "        id_vars=['Date'],\n",
    "        var_name='series_name',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Add metadata\n",
    "    long_df['frequency'] = frequency\n",
    "    long_df['source_file'] = source_file\n",
    "    \n",
    "    # Convert value to numeric\n",
    "    long_df['value'] = pd.to_numeric(long_df['value'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with null values\n",
    "    long_df = long_df.dropna(subset=['value'])\n",
    "    \n",
    "    return long_df\n",
    "\n",
    "if rbi_standardized:\n",
    "    # Convert all to long format\n",
    "    long_dfs = []\n",
    "    for filename, df in rbi_standardized.items():\n",
    "        frequency = FREQUENCY_MAP.get(filename, 'unknown')\n",
    "        long_df = wide_to_long(df, frequency, filename)\n",
    "        long_dfs.append(long_df)\n",
    "        print(f\"{filename}: {len(long_df)} observations in long format\")\n",
    "\n",
    "    # Combine all\n",
    "    rbi_long = pd.concat(long_dfs, ignore_index=True)\n",
    "    print(f\"\\nTotal observations: {len(rbi_long):,}\")\n",
    "else:\n",
    "    print(\"No standardized RBI data to convert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identify Unique Series & Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.501500Z",
     "iopub.status.busy": "2026-02-01T09:26:35.501132Z",
     "iopub.status.idle": "2026-02-01T09:26:35.543571Z",
     "shell.execute_reply": "2026-02-01T09:26:35.541831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique macro series: 99\n",
      "\n",
      "Series with 5+ years of data: 88\n",
      "Series with 10+ years of data: 59\n"
     ]
    }
   ],
   "source": [
    "if 'rbi_long' in locals():\n",
    "    # Get unique series\n",
    "    series_list = rbi_long['series_name'].unique()\n",
    "    print(f\"Unique macro series: {len(series_list)}\")\n",
    "\n",
    "    # Calculate coverage per series\n",
    "    coverage = rbi_long.groupby(['series_name', 'frequency']).agg(\n",
    "        start_date=('Date', 'min'),\n",
    "        end_date=('Date', 'max'),\n",
    "        observations=('value', 'count'),\n",
    "        mean_value=('value', 'mean'),\n",
    "        std_value=('value', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate years of data\n",
    "    coverage['years'] = (coverage['end_date'] - coverage['start_date']).dt.days / 365.25\n",
    "    coverage = coverage.sort_values('years', ascending=False)\n",
    "\n",
    "    print(f\"\\nSeries with 5+ years of data: {(coverage['years'] >= 5).sum()}\")\n",
    "    print(f\"Series with 10+ years of data: {(coverage['years'] >= 10).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.547874Z",
     "iopub.status.busy": "2026-02-01T09:26:35.547347Z",
     "iopub.status.idle": "2026-02-01T09:26:35.562897Z",
     "shell.execute_reply": "2026-02-01T09:26:35.561177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Series by Data Coverage:\n",
      "                                          series_name frequency start_date  \\\n",
      "74                   OTHER DEPOSITS WITH RESERVE BANK   monthly 1951-03-01   \n",
      "48                     DEMAND DEPOSITS WITH THE BANKS   monthly 1951-03-01   \n",
      "38                           CURRENCY WITH THE PUBLIC   monthly 1951-03-01   \n",
      "67                                                 M3   monthly 1951-03-01   \n",
      "65                                                 M1   monthly 1951-03-01   \n",
      "37  CREDIT TO THE COMMERCIAL SECTOR BY THE BANKING...   monthly 1961-03-01   \n",
      "68                        MARKET CAPITALISATION - BSE   monthly 1980-03-01   \n",
      "56                              FOREIGN TRADE IMPORTS   monthly 1990-04-01   \n",
      "55                              FOREIGN TRADE EXPORTS   monthly 1990-04-01   \n",
      "66                                                 M2   monthly 1994-03-01   \n",
      "90  SUM OF CREDIT TO THE GOVERNMENT & CREDIT TO TH...   monthly 1999-04-01   \n",
      "52                                     FISCAL DEFICIT   monthly 2000-03-01   \n",
      "93                                  TOTAL EXPENDITURE   monthly 2000-03-01   \n",
      "73      ON REVENUE ACCOUNT OF WHICH INTEREST PAYMENTS   monthly 2000-03-01   \n",
      "62                              GROSS PRIMARY DEFICIT   monthly 2000-03-01   \n",
      "94                                      TOTAL REVENUE   monthly 2000-03-01   \n",
      "80              RBI BALANCE SHEET-DOMESTIC-SECURITIES   monthly 2004-07-01   \n",
      "78                           RBI BALANCE SHEET-ASSETS   monthly 2004-07-01   \n",
      "79                         RBI BALANCE SHEET-CURRENCY   monthly 2004-07-01   \n",
      "82                      RBI BALANCE SHEET-LOANS-BANKS   monthly 2004-07-01   \n",
      "\n",
      "     end_date      years  observations  \n",
      "74 2026-01-01  74.839151           899  \n",
      "48 2026-01-01  74.839151           899  \n",
      "38 2026-01-01  74.839151           899  \n",
      "67 2026-01-01  74.839151           899  \n",
      "65 2025-11-01  74.672142           897  \n",
      "37 2026-01-01  64.837782           412  \n",
      "68 2025-11-01  45.670089           404  \n",
      "56 2025-11-01  35.586585           428  \n",
      "55 2025-11-01  35.586585           428  \n",
      "66 2025-11-01  31.671458           381  \n",
      "90 2026-01-01  26.754278           320  \n",
      "52 2025-11-01  25.670089           232  \n",
      "93 2025-11-01  25.670089           232  \n",
      "73 2025-11-01  25.670089           232  \n",
      "62 2025-11-01  25.670089           232  \n",
      "94 2025-11-01  25.670089           232  \n",
      "80 2026-01-01  21.503080           259  \n",
      "78 2025-12-01  21.418207           258  \n",
      "79 2025-12-01  21.418207           258  \n",
      "82 2025-12-01  21.418207           249  \n"
     ]
    }
   ],
   "source": [
    "if 'coverage' in locals():\n",
    "    # Show top series by coverage\n",
    "    print(\"Top 20 Series by Data Coverage:\")\n",
    "    print(coverage.head(20)[['series_name', 'frequency', 'start_date', 'end_date', 'years', 'observations']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.567383Z",
     "iopub.status.busy": "2026-02-01T09:26:35.566997Z",
     "iopub.status.idle": "2026-02-01T09:26:35.585348Z",
     "shell.execute_reply": "2026-02-01T09:26:35.583845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series by Frequency:\n",
      "             num_series  avg_years  total_obs\n",
      "frequency                                    \n",
      "daily                 7       10.7      20515\n",
      "fortnightly           2        7.9        412\n",
      "monthly              44       24.9      11724\n",
      "quarterly            27       10.0        682\n",
      "weekly               19        8.6       8551\n"
     ]
    }
   ],
   "source": [
    "if 'coverage' in locals():\n",
    "    # Count series by frequency\n",
    "    freq_summary = coverage.groupby('frequency').agg(\n",
    "        num_series=('series_name', 'count'),\n",
    "        avg_years=('years', 'mean'),\n",
    "        total_obs=('observations', 'sum')\n",
    "    ).round(1)\n",
    "\n",
    "    print(\"Series by Frequency:\")\n",
    "    print(freq_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filter Usable Series (5+ years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.591249Z",
     "iopub.status.busy": "2026-02-01T09:26:35.590568Z",
     "iopub.status.idle": "2026-02-01T09:26:35.612481Z",
     "shell.execute_reply": "2026-02-01T09:26:35.610966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable series (5+ years): 88\n",
      "Filtered observations: 41,656\n"
     ]
    }
   ],
   "source": [
    "if 'coverage' in locals():\n",
    "    # Keep only series with 5+ years of data\n",
    "    usable_series = coverage[coverage['years'] >= 5]['series_name'].tolist()\n",
    "    rbi_long_filtered = rbi_long[rbi_long['series_name'].isin(usable_series)].copy()\n",
    "\n",
    "    print(f\"Usable series (5+ years): {len(usable_series)}\")\n",
    "    print(f\"Filtered observations: {len(rbi_long_filtered):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:26:35.617870Z",
     "iopub.status.busy": "2026-02-01T09:26:35.617255Z",
     "iopub.status.idle": "2026-02-01T09:26:35.741045Z",
     "shell.execute_reply": "2026-02-01T09:26:35.739042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved: ..\\data_processed\\rbi_macro_all_long.parquet\n",
      "âœ“ Saved: ..\\data_processed\\rbi_macro_coverage.parquet\n"
     ]
    }
   ],
   "source": [
    "if 'rbi_long' in locals():\n",
    "    # Save full long-format data\n",
    "    output_path = PROCESSED_PATH / 'rbi_macro_all_long.parquet'\n",
    "    rbi_long.to_parquet(output_path, index=False)\n",
    "    print(f\"âœ“ Saved: {output_path}\")\n",
    "\n",
    "if 'coverage' in locals():\n",
    "    # Save coverage table\n",
    "    coverage_path = PROCESSED_PATH / 'rbi_macro_coverage.parquet'\n",
    "    coverage.to_parquet(coverage_path, index=False)\n",
    "    print(f\"âœ“ Saved: {coverage_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
